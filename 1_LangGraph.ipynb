{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b444fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8411fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "#Provide your key directly\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "768fd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the state schema\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    retriever: object\n",
    "    route: str\n",
    "    source: str\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c87377de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create graph\n",
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d8a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47cf9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2️⃣ Output parser for routing\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"route\", description=\"RAG, WIKI, ARXIV, or LLM\"),\n",
    "    ResponseSchema(name=\"answer\", description=\"Answer if LLM is chosen, else empty string\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8690016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Node functions ---\n",
    "\n",
    "def router_node(state):\n",
    "    query = state[\"query\"]\n",
    "    prompt = f\"\"\"\n",
    "Decide which source to use for this question:\n",
    "- RAG: AWS/AI Practitioner PDF and AWS related questions\n",
    "- WIKI: Wikipedia/general knowledge\n",
    "- ARXIV: Research papers\n",
    "- LLM: Anything else\n",
    "\n",
    "Respond with exactly one word: RAG, WIKI, ARXIV, or LLM\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "    route = llm.invoke(prompt).content.strip().upper()\n",
    "    state[\"route\"] = route\n",
    "    return state\n",
    "\n",
    "def rag_node(state):\n",
    "    retriever = state.get(\"retriever\")\n",
    "    if not retriever:\n",
    "        state[\"answer\"] = \"No retriever available for RAG.\"\n",
    "    else:\n",
    "        state[\"answer\"] = RetrievalQA.from_chain_type(llm=llm, retriever=retriever).run(state[\"query\"])\n",
    "    state[\"source\"] = \"RAG\"\n",
    "    return state\n",
    "\n",
    "def wiki_node(state):\n",
    "    tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    state[\"answer\"] = tool.run(state[\"query\"])\n",
    "    state[\"source\"] = \"WIKI\"\n",
    "    return state\n",
    "\n",
    "def arxiv_node(state):\n",
    "    api = ArxivAPIWrapper()\n",
    "    state[\"answer\"] = api.run(state[\"query\"])\n",
    "    state[\"source\"] = \"ARXIV\"\n",
    "    return state\n",
    "\n",
    "def llm_node(state):\n",
    "    state[\"answer\"] = llm.predict(state[\"query\"])\n",
    "    state[\"source\"] = \"LLM\"\n",
    "    return state\n",
    "\n",
    "def refine_node(state):\n",
    "    prompt = f\"\"\"\n",
    "Refine and summarize the answer clearly.\n",
    "Question: {state['query']}\n",
    "Answer: {state['answer']}\n",
    "\"\"\"\n",
    "    state[\"answer\"] = llm.invoke(prompt).content\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13d8e7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23c2ea8dba0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Graph setup ---\n",
    "\n",
    "State = dict\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"router\", router_node)\n",
    "graph.add_node(\"rag\", rag_node)\n",
    "graph.add_node(\"wiki\", wiki_node)\n",
    "graph.add_node(\"arxiv\", arxiv_node)\n",
    "graph.add_node(\"llm\", llm_node)\n",
    "graph.add_node(\"refine\", refine_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8621d145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23c2ea8dba0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional edges from router\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda s: s[\"route\"],\n",
    "    {\n",
    "        \"RAG\": \"rag\",\n",
    "        \"WIKI\": \"wiki\",\n",
    "        \"ARXIV\": \"arxiv\",\n",
    "        \"LLM\": \"llm\"\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd214cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23c2ea8dba0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All tool nodes go to refine\n",
    "graph.add_edge(\"rag\", \"refine\")\n",
    "graph.add_edge(\"wiki\", \"refine\")\n",
    "graph.add_edge(\"arxiv\", \"refine\")\n",
    "graph.add_edge(\"llm\", \"refine\")\n",
    "\n",
    "# End the workflow\n",
    "graph.add_edge(\"refine\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6402f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set entry point and compile\n",
    "graph.set_entry_point(\"router\")\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "066ce121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source: RAG\n",
      "Answer:\n",
      " AWS SageMaker is a fully managed service that enables developers and data scientists to build, train, and deploy machine learning models quickly and efficiently. It provides a range of tools and features for data preparation, model training, tuning, and deployment, making it easier to integrate machine learning into applications.\n"
     ]
    }
   ],
   "source": [
    "# --- Example usage ---\n",
    "query = \"What is AWS sagemaker?\"\n",
    "result = workflow.invoke({\"query\": query, \"retriever\": None})\n",
    "print(\"\\nSource:\", result[\"source\"])\n",
    "print(\"Answer:\\n\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12034d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
